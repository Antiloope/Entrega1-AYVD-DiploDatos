# -*- coding: utf-8 -*-
"""ej2c.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pJorgswJW1m0gKKxemB6fGW6zqicGSqz
"""

import io
import matplotlib
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns

sns.set_context('talk')

"""## Lectura del dataset

En la notebook 00 se explican los detalles de la siguiente sección.
"""

url = 'https://cs.famaf.unc.edu.ar/~mteruel/datasets/diplodatos/sysarmy_survey_2020_processed.csv'
df = pd.read_csv(url)

df[:3]

"""# EJERCICIO 2 C:

"""

#Se procede a seleccionar las columnas y filas relevantes para analizar. En este punto, las columnas a analizar serán
#profile_studies_level y salary_monthly_NETO
#En primer lugar se procede a verificar que no existan valores nulos en la columna "profile_studies_level"

df_psl_null_nan = df[(df['profile_studies_level'].isnull()) &
                     (df.profile_studies_level.isna())]
print(df_psl_null_nan)

#Luego se procede a filtrar los valores extremos de la columna "salary_monthly_NETO".
#Tal como en el punto 1, se consideran como extremos los valores de sueldos por encima del percentil 95 y por debajo del 5.
#Una vez identificado los extremos, se eliminan los resultados inválidos.

min_salary = df.salary_monthly_NETO.quantile(0.05)
max_salary = df.salary_monthly_NETO.quantile(0.95)

filter = df[(df['salary_monthly_NETO'] > min_salary) & (df['salary_monthly_NETO'] < max_salary)]

#Posteriormente procedemos a identificar las subpoblaciones más numerosas, según nivel de fomración o estudio.
#Para facilitar su identificación se crean grupos según el nivel de estudio y se los ordena en forma descendente según la cantidad de 
#registros que integren cada subgrupo.

filter[['profile_studies_level']].groupby(['profile_studies_level'])['profile_studies_level'] \
                             .count() \
                             .reset_index(name='count') \
                             .sort_values(['count'], ascending=False)

#Luego se genera un gráfico para visualizar las cantidades por grupos, obtenidas en el paso anterior.

sorted_studies_levels = ['Primario', 'Secundario', 'Terciario', 'Universitario',
                         'Posgrado', 'Doctorado', 'Posdoctorado'] #lista de los nombres de categorías ordenadas

g =sns.catplot(x="profile_studies_level", kind="count", palette="ch:.25", data=filter,order=sorted_studies_levels,
               height = 5.5, aspect = 1.5)
plt.tick_params(labelrotation=30)

#Como se puede apreciar, tanto en la tabla como en el gráfico de barras, se observa que los subgrupos más numerosos son 
#el del Nivel Universitario (3569 registros) y el del Nivel Terciario (1020 registros).
#En base a esto, se crean dos subdatasets (uno para cada grupo) y se grafican de forma comparativa en un histograma
#que permita visualizar el salario de cada subgrupo y su distribución.
#En el histograma se observa que para ambos grupos, los valores salariales se conentran en los montos
#inferiors al millón. Y entre ambos grupos, los programadores con formación universitaria predominan. Es decir,
#hay mayor cantidad de universitarios que cobran rangos de sueldos similares a los de aquellos con formación terciaria.
#Una posible conclusión de esta visualización, es que el nivel de formación no es una variable que por sí sola determine
#un mayor ingreso salarial.
#Aunque por otro lado, entre los valores salariales más altos, predominan aquellos programadores que tienen una formación universitaria
#Quizás este último escenario pueda explicarse por alguna variable extra como mayor cantidad de años de experiencia.

df_universitario= filter[ filter['profile_studies_level']=='Universitario']
df_terciario=filter[ filter['profile_studies_level']=='Terciario']

plt.hist(df_universitario['salary_monthly_NETO'], color='orangered', bins=50)
plt.hist(df_terciario['salary_monthly_NETO'], color='steelblue', bins=50) #aca importa el orden, cuidado con la superposición
plt.show()

"""¿Considera que ambas variables son independientes? ¿Qué analizaría al respecto?"""

#Al analizar la dependencia o independencia de las variables estudiadas (salario neto y nivel de formación),
#una regla que podemos verificar si se cumple o no es aquella que plantea P(X=x, Y=y)=P(X=x). P(Y=y). En otras palabras,
#determinar si la probabilidad conjunta entre X e Y, es igual al producto de las probabilidades marginales de X y de Y.
#Para esto planteamos las siguientes probabilidades para verificar la igualdad indicada por la regla mencionada. Se quiere 
#verificar si la probablidad conjunta entre tener un salario mayor al salario promedio y ser universitario, es igual al producto
#entre las probabilidades marginales de ganar un salario mayor al salario promedio y la de ser universitario.


#Caluclamos el salario primedio
avg_salary = filter['salary_monthly_NETO'].mean()
avg_salary

is_above_avg = filter[filter['salary_monthly_NETO'] > avg_salary]
universitario = filter[ filter['profile_studies_level']=='Universitario']

#Calculamos la probabilidad marginal de ser universitario
prob_marginal_universitario = len(universitario)/len(filter)
prob_marginal_universitario

#Calculamos la probabilidad de ganar un salario mayor al salario promedio
prob_marginal_above_avg = len(is_above_avg) / len(filter)
prob_marginal_above_avg

#Calculamos el producto entre las probabilidades marginales
prod_probs_marginales = prob_marginal_universitario * prob_marginal_above_avg
prod_probs_marginales

#Obtenemos la intersección entre las variables
intersection_count = len(filter.query('profile_studies_level.str.contains("Universitario") and salary_monthly_NETO > salary_monthly_NETO.mean()' , engine='python'))

#Calculamos la probabilidad conjunta
prob_conjunta = intersection_count / len(filter)
prob_conjunta

#Aquí se puede observar que la probabilidad conjunta es diferente al producto de las probabilidades marginales.
#En consecuencia, se demuestra que ambas variables no son independientes.

print(f"Probabilidad conjunta: {prob_conjunta}")
print(f"Producto de las probabilidades marginales:{prob_marginal_above_avg}")

#La conclusión del punto anterior se puede rectficar con el siguiente ejercicio.
#Se quiere validar si se cumple o no la regla que plantea P(X=x|Y=y)=P(X=x). Es decir, si la probablidad condicional
#de X dado Y, es igual a la probabilidad marginal de X. En el caso analizado, consistiría en determinar si
#la probabilidad condiconal de ganar por encima del salario que representa la mediana dado que se tiene una formación 
#terciaria es igual a la probabilidad marginal de ganar por encima de la mediana.

#Se calcula la mediana
median_salary = filter['salary_monthly_NETO'].median()
median_salary

is_above_median = filter[filter['salary_monthly_NETO'] > median_salary]
terciario = filter[ filter['profile_studies_level']=='Terciario']

#Se calcula la probabilidad marginal de ganar por encima de la mediana
p_above_median = len(is_above_median) /len(filter)

intersection_count = len(filter.query('profile_studies_level.str.contains("Terciario") and salary_monthly_NETO > salary_monthly_NETO.median()' , engine='python'))

#Se calcula la probabilidad condicional de ganar por encima de la mediana dado que se tiene formación terciaria
p_condic_above_median = intersection_count/len(terciario)

#Aquí se puede observar que la probabilidad condicional es diferente de la probabilidad marginal
#En conclusión, las variables analizadas no son independientes, y se pudo demostrar mediante las diferencias obtenidas 
#dado que "P(X=x, Y=y) <> P(X=x).P(Y=y)", y "P(X=x|Y=y) <> P(X=x)".
#NOTA: el simbolo "<>" representa diferente.

print(f"Probabilidad condicional: {p_condic_above_median}")
print(f"Probabilidad marginal: {p_above_median}")

"""Calcule medidas de centralización y dispersión para cada subpoblación"""

#A continuación se calculan algunas medidas de centralización y disperción para cada subpoblación.

#Subgrupo "Universitario"
#Medidas de Centralización

print(f"Media: {df_universitario['salary_monthly_NETO'].mean()}")
print(f"Mediana: {df_universitario['salary_monthly_NETO'].median()}")
print(f"Moda: {df_universitario['salary_monthly_NETO'].mode()}")

#Medidas de Dispersión

print(f"Varianza: {df_universitario['salary_monthly_NETO'].var()}")
print(f"Desviación Estandar: {df_universitario['salary_monthly_NETO'].std()}")
print(f"Coeficiente de variación: {df_universitario['salary_monthly_NETO'].std()/df_universitario['salary_monthly_NETO'].mean()}")



#Subgrupo "Terciario"
#Medidas de Centralización

print(f"Media: {df_terciario['salary_monthly_NETO'].mean()}")
print(f"Mediana:{df_terciario['salary_monthly_NETO'].median()}")
print(f"Moda: {df_terciario['salary_monthly_NETO'].mode()}")

#Medidas de Dispersión

print(f"Varianza: {df_terciario['salary_monthly_NETO'].var()}")
print(f"Desviación Estandar: {df_terciario['salary_monthly_NETO'].std()}")
print(f"Coeficiente de varianción: {df_terciario['salary_monthly_NETO'].std()/df_terciario['salary_monthly_NETO'].mean()}")

#A modo de conclusión, si se comparan ambos subgrupos, en base al coeficiente de variación se puede ver que en ambos casos la
#dispersión de los datos con respecto a la media es alta. Pero en el caso del grupo "Terciario" es mayor, dado que tiene un mayor valor